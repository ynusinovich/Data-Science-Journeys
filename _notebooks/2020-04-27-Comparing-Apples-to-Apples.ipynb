{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Comparing Apples to Apples\"\n",
    "> \"A first look at computer vision with a support vector classifier model.\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [image processing, computer vision, classification]\n",
    "- hide: false\n",
    "- search_exclude: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "### What is computer vision?\n",
    "Computer vision is teaching your computer to understand and classify the information in images and videos.\n",
    "\n",
    "For this post, I will review how to code a simple algorithm that differentiates between pictures of **apples and oranges**.\n",
    "\n",
    "We will be using the open source computer vision (**OpenCV**) library, the [most popular computer vision library](https://hub.packtpub.com/top-10-computer-vision-tools/).\n",
    "\n",
    "## Examples\n",
    "### What do we use computer vision for?\n",
    "Examples adapted from [this blog post](https://machinelearningmastery.com/what-is-computer-vision/).\n",
    "- Optical character recognition (OCR)\n",
    "- Retail (e.g. automated checkouts)\n",
    "- Medical imaging\n",
    "- Merging computer-generated imagery (CGI) with live actors in movies\n",
    "- Surveillance\n",
    "- Fingerprint recognition and biometrics\n",
    "\n",
    "## Code\n",
    "### How to train a simple computer vision model.\n",
    "### *Download Photographs*\n",
    "Start by downloading pictures of apples and oranges and putting them into separate folders called `Apples` and `Oranges`.\n",
    "\n",
    "Ideally you should have [at least 50 photos](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
    "\n",
    "Possible sources:\n",
    "\n",
    "- Apples (8 varieties) and oranges (1 variety) from the [Fruits 360 Kaggle competition dataset](https://www.kaggle.com/moltean/fruits).\n",
    "- [Google Images](https://www.google.com/imghp?hl=en) search.\n",
    "- Search through the [ImageNet database](http://image-net.org/).\n",
    "\n",
    "### *Import Libraries*\n",
    "Import the libraries we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will use the [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) for this model, which will draw a barrier (hyperplane) to distinctively classify the features of images of oranges from the features of images of apples.\n",
    "\n",
    "### *Convert the Images*\n",
    "This function generates an array from a folder of fruit photos, as well as a list of corresponding labels. We then use this code on the <mark>Oranges</mark> and <mark>Apples</mark> subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fruit_listing(directory_path = \"Fruit/\", fruit_type = \"fruit\", resolution = (128, 128)):\n",
    "    fruit_list = []\n",
    "    directory = directory_path\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.startswith('.'):\n",
    "            fruit_list.append(cv2.resize(cv2.imread(f\"{directory}{filename}\", 1), resolution))\n",
    "    fruit_labels = []\n",
    "    for i in range(0,len(fruit_list)):\n",
    "        fruit_labels.append(fruit_type)\n",
    "    return fruit_list, fruit_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orange_list, orange_labels = fruit_listing(directory_path = \"Oranges/\", fruit_type = \"orange\")\n",
    "apple_list, apple_labels = fruit_listing(directory_path = \"Apples/\", fruit_type = \"apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden files starting with `.` were excluded. (My computer automatically generated the folder attribute file `.DS_Store` in both the `Oranges` and `Apples` folders, but this file is clearly neither an orange nor an apple.)\n",
    "\n",
    "The files are all resized to `128 x 128`. A higher resolution would slow down the modelling but may result in a more accurate model.\n",
    "\n",
    "Please note that my photos were located in subdirectories of my Juypter notebook's directory. If yours aren't, then you'll have to type out the whole `directory_path` when calling the function.\n",
    "\n",
    "### *Create X and y (Features and Target):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_array = np.stack(orange_list + apple_list, axis = 3)\n",
    "fruit_label_array = np.array(orange_labels + apple_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fruit_array\n",
    "y = fruit_label_array\n",
    "\n",
    "X = X.reshape(X.shape[0] * X.shape[1] * X.shape[2], X.shape[3]).T\n",
    "y = y.reshape(y.shape[0],)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data must be reshaped to turn the feature array from 3-dimensional (pixel x-coordinate, pixel y-coordinate, and pixel color) into 1-dimensional (pixel features). The lines for reshaping the feature array are from [this blog post](https://blog.hyperiondev.com/index.php/2019/02/18/machine-learning/).\n",
    "\n",
    "### *Train Model and Check Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "preds = svc.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My accuracy was 91% with the base support vector classifier. Tuning the hyperparameters could get you an even better result, but I'll leave that part out since hyperparameter tuning is not the focus of this blog post.\n",
    "\n",
    "### *Check Model on New Test Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fruit_prediction(filename = \"test.jpg\", resolution = (128, 128)):\n",
    "    test_fruit = cv2.resize(cv2.imread(f\"{filename}\", 1), resolution)\n",
    "    test_fruit = test_fruit.reshape(test_fruit.shape[0] * test_fruit.shape[1] * test_fruit.shape[2], 1).T\n",
    "    return svc.predict(test_fruit)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'orange'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_prediction(filename = \"test-orange.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_prediction(filename = \"test-apple.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly classified the test orange and test apple!\n",
    "\n",
    "Please note that my test orange and test apple were located in my Juypter notebook's main directory. If yours aren't, then you'll have to change the function above to access their actual paths.\n",
    "\n",
    "Now you're ready for the next step, [image classification with a convolutional neural network](https://www.tensorflow.org/tutorials/images/classification)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
